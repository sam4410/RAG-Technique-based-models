# RAG-Technique-based-models

### RAG Pipeline.ipynb

This notebook illustrates the 3 major components involved in building an end to end RAG based generative artificial intellligence application. The 3 components are:
1. Data collection and preprocessing
2. Data embedding and storage
3. Input augementation and response generation


### Semantic Search Engine and Generative Agent using Index-Based Search on RAG
This approach decomposes the entire RAG (Retrieval Augmented Generation) pipeline into three distinct components:

1. Data collection and preprocessing
2. Data embedding and storage
3. Index-based RAG

The project explores the transformative impact of index-based search on RAG, introducing a pivotal advancement: full traceability. Documents are structured as nodes containing data chunks, with query sources traceable back to the original data. Indexes significantly enhance retrieval speedâ€”critical as datasets grow in volume.
A key innovation is the integration of complementary technologies: LlamaIndex, Deep Lake, and OpenAI. The project utilizes documents on "Drone Technology" advancements to demonstrate essential system-building tools, including:

* Vector stores
* Dataset management
* Chunking strategies
* Embedding techniques
* Node creation
* Ranking methodologies
* Indexing methods

The implementation leverages the LlamaIndex framework, Deep Lake vector stores, and OpenAI's models. Python tools were developed to construct these systems efficiently.
The project highlights the crucial role of various index types (vector, tree, list, and keyword) in providing greater control over generative AI applications, enabling precise adjustments and improvements. Additionally, it introduces performance metrics to evaluate both response quality and retrieval time efficiency.
